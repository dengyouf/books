{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Material for MkDocs","text":"<p>Welcome to Material for MkDocs.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"k8s/harbor/","title":"\u4f01\u4e1a\u7ea7Harbor\u955c\u50cf\u4ed3\u5e93","text":""},{"location":"k8s/harbor/#_1","title":"\u4e3b\u673a\u73af\u5883\u51c6\u5907","text":"<p>\u4f7f\u7528Docker\u5feb\u901f\u90e8\u7f72Harbor\u955c\u50cf\u4ed3\u5e93\uff0c\u64cd\u4f5c\u7cfb\u7edf\u4e3aUbuntu 24.04.2 LTS(noble)\uff0c\u7528\u5230\u7684\u5404\u76f8\u5173\u7a0b\u5e8f\u7248\u672c\u5982\u4e0b:</p>"},{"location":"k8s/harbor/#1","title":"1.\u4e3b\u673a\u540d\u89e3\u6790","text":"<pre><code>hostnamectl  set-hostname harbor.devops.io\necho \"192.168.1.250 harbor.devops.io harbor\" &gt;&gt; /etc/hosts\n</code></pre>"},{"location":"k8s/harbor/#2selinux","title":"2.\u5173\u95ed\u9632\u706b\u5899\u548cselinux","text":"<pre><code>systemctl disable --now ufw\n</code></pre>"},{"location":"k8s/harbor/#3","title":"3.\u65f6\u95f4\u540c\u6b65","text":"<pre><code>timedatectl  set-timezone Asia/Shanghai\napt install -y chrony\ncat  &gt; /etc/chrony/chrony.conf &lt;&lt; 'EOF'\npool ntp.aliyun.com       iburst maxsources 4\nkeyfile /etc/chrony/chrony.keys\ndriftfile /var/lib/chrony/chrony.drift\nlogdir /var/log/chrony\nmaxupdateskew 100.0\nrtcsync\nmakestep 1 3\nEOF\nsystemctl restart chrony.service &amp;&amp; systemctl  enable chrony.service\nchronyc sources\n</code></pre>"},{"location":"k8s/harbor/#4","title":"4.\u5f00\u542f\u5185\u6838\u8f6c\u53d1","text":"<pre><code>cat &gt; /etc/sysctl.d/99-kubernetes-cri.conf &lt;&lt;EOF\nnet.bridge.bridge-nf-call-iptables  = 1\nnet.ipv4.ip_forward                 = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nEOF\nsysctl  --system\n</code></pre>"},{"location":"k8s/harbor/#docker","title":"\u5b89\u88c5docker","text":""},{"location":"k8s/harbor/#1docker","title":"1.\u5b89\u88c5docker","text":"<pre><code>sudo apt-get remove docker docker-engine docker.io\nsudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common\ncurl -fsSL https://mirrors.huaweicloud.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -\nsudo add-apt-repository \"deb [arch=amd64] https://mirrors.huaweicloud.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"\nsudo apt-get update\nsudo apt-get install -y docker-ce\n docker version\nClient: Docker Engine - Community\n Version:           28.5.1\n API version:       1.51\n Go version:        go1.24.8\n Git commit:        e180ab8\n Built:             Wed Oct  8 12:17:26 2025\n OS/Arch:           linux/amd64\n Context:           default\n\nServer: Docker Engine - Community\n Engine:\n  Version:          28.5.1\n  API version:      1.51 (minimum version 1.24)\n  Go version:       go1.24.8\n  Git commit:       f8215cc\n  Built:            Wed Oct  8 12:17:26 2025\n  OS/Arch:          linux/amd64\n  Experimental:     false\n containerd:\n  Version:          v1.7.28\n  GitCommit:        b98a3aace656320842a23f4a392a33f46af97866\n runc:\n  Version:          1.3.0\n  GitCommit:        v1.3.0-0-g4ca628d1\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\n</code></pre>"},{"location":"k8s/harbor/#2docker","title":"2.\u914d\u7f6edocker\u6570\u636e\u76ee\u5f55","text":"<pre><code>systemctl stop docker docker.socket\nmkdir /data\nmv /var/lib/docker /data/\nln -sv /data/docker /var/lib/docker\nsystemctl  enable docker --now\n</code></pre>"},{"location":"k8s/harbor/#3_1","title":"3.\u914d\u7f6e\u52a0\u901f\u5668","text":"<pre><code>tee  /etc/docker/daemon.json &lt;&lt; 'EOF'\n{\n    \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n    \"registry-mirrors\": [\n         \"https://o4uba187.mirror.aliyuncs.com\",\n         \"https://docker.1ms.run\",\n         \"https://docker.1panel.live\"\n    ]\n}\nEOF\nsystemctl daemon-reload\n</code></pre>"},{"location":"k8s/harbor/#harbor_1","title":"\u5b89\u88c5Harbor","text":""},{"location":"k8s/harbor/#1_1","title":"1.\u83b7\u53d6\u79bb\u7ebf\u5305","text":"<pre><code>wget https://ghfast.top/https://github.com/goharbor/harbor/releases/download/v2.14.0/harbor-offline-installer-v2.14.0.tgz\ntar -xf harbor-offline-installer-v2.14.0.tgz  -C /data/\n</code></pre>"},{"location":"k8s/harbor/#2","title":"2.\u751f\u6210\u8bc1\u4e66","text":"<pre><code>mkdir /data/harbor/ssl\ncd /data/harbor/ssl\n# 1. Generate a CA certificate private key.\nopenssl genrsa -out ca.key 4096\n# 2. Generate the CA certificate.\nopenssl req -x509 -new -nodes -sha512 -days 3650 \\\n -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=harbor.devops.io\" \\\n -key ca.key \\\n -out ca.crt\n# 3. Generate a private key for harbor server.\nopenssl genrsa -out harbor.devops.io.key 4096\n# 4. Generate a certificate signing request (CSR).\nopenssl req -sha512 -new \\\n    -subj \"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=harbor.devops.io\" \\\n    -key harbor.devops.io.key \\\n    -out harbor.devops.io.csr\n# 5. Generate an x509 v3 extension file.\ncat &gt; v3.ext &lt;&lt;-EOF\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.1=harbor.devops.io\nDNS.2=harbor.devops.io\nDNS.3=192.168.1.250\nEOF\n# 6. Use the v3.ext file to generate a certificate for your Harbor host.\nopenssl x509 -req -sha512 -days 3650 \\\n    -extfile v3.ext \\\n    -CA ca.crt -CAkey ca.key -CAcreateserial \\\n    -in harbor.devops.io.csr \\\n    -out harbor.devops.io.crt\nCertificate request self-signature ok\nsubject=C = CN, ST = Beijing, L = Beijing, O = example, OU = Personal, CN = harbor.devops.io\n</code></pre>"},{"location":"k8s/harbor/#3harboryml","title":"3.\u914d\u7f6eharbor.yml","text":"<pre><code>cd /data/harbor/\ncp harbor.yml.tmpl harbor.yml\nvim /data/harbor/harbor.yml\nhostname: harbor.devops.io\n\n# http related config\nhttp:\n  # port for http, default is 80. If https enabled, this port will redirect to https port\n  port: 80\n\n# https related config\nhttps:\n  # https port for harbor, default is 443\n  port: 443\n  # The path of cert and key files for nginx\n  certificate: /data/harbor/ssl/harbor.devops.io.crt\n  private_key: /data/harbor/ssl/harbor.devops.io.key\n</code></pre>"},{"location":"k8s/harbor/#4prepare","title":"4.\u6267\u884cprepare\u811a\u672c","text":"<pre><code>docker load -i /data/harbor/harbor.v2.14.0.tar.gz\ncd /data/harbor/ &amp;&amp; ./prepare\n</code></pre>"},{"location":"k8s/harbor/#5install","title":"5.\u6267\u884cinstall\u811a\u672c","text":"<pre><code>./install.sh\n</code></pre>"},{"location":"k8s/harbor/#6ui","title":"6.\u8bbf\u95eeUI","text":""},{"location":"k8s/harbor/#docker_1","title":"\u914d\u7f6edocker\u4f7f\u7528","text":""},{"location":"k8s/harbor/#1_2","title":"1.\u914d\u7f6e\u8ba4\u8bc1\u8bc1\u4e66","text":"<pre><code># \u8f6c\u6362\u8bc1\u4e66\ncd /data/harbor/ssl\nopenssl x509 -inform PEM -in harbor.devops.io.crt -out harbor.devops.io.cert\n\nmkdir -pv  /etc/docker/certs.d/harbor.devops.io/\ncp /data/harbor/ssl/{harbor.devops.io.cert,harbor.devops.io.key,ca.crt} /etc/docker/certs.d/harbor.devops.io/\n</code></pre>"},{"location":"k8s/harbor/#2_1","title":"2.\u4e0a\u4f20\u955c\u50cf","text":"<pre><code>docker pull ikubernetes/myapp:v1\ndocker tag  ikubernetes/myapp:v1 harbor.devops.io/library/myapp:v1\ndocker login harbor.devops.io -u admin -p Harbor12345\ndocker push harbor.devops.io/library/myapp:v1\n</code></pre>"},{"location":"k8s/harbor/#containerd","title":"\u914d\u7f6econtainerd\u4f7f\u7528","text":"<pre><code># \u914d\u7f6econfig_path\u8def\u5f84\ngrep -B 2 config_path /etc/containerd/config.toml\n    [plugins.\"io.containerd.grpc.v1.cri\".registry]\n      config_path = \"/etc/containerd/certs.d\"\nsystemctl restart containerd\nmkdir -pv /etc/containerd/certs.d/harbor.devops.io\nscp harbor.devops.io:/data/harbor/ssl/ca.crt /etc/containerd/certs.d/harbor.devops.io\ncat &gt; /etc/containerd/certs.d/harbor.devops.io/hosts.toml  &lt;&lt; 'EOF'\nserver = \"https://harbor.devops.io\"\n[host.\"https://harbor.devops.io\"]\n  capabilities = [\"pull\", \"resolve\",\"push\"]\n  skip_verify = false\n  ca = [\"ca.crt\"]\nEOF\n</code></pre>"},{"location":"k8s/harbor/#1podsecret","title":"1.\u914d\u7f6ePod\u62c9\u53bbSecret","text":"<pre><code>kubectl create secret docker-registry harbor-secret \\\n  --docker-server=harbor.devops.io \\\n  --docker-username=admin \\\n  --docker-password=Harbor12345 \\\n  --docker-email=harbro@devops.com \\\n  -n kube-system\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/","title":"Kubeadm \u5b89\u88c5 Kubernetes v1.30.12(Containerd)","text":""},{"location":"k8s/kubeadm-v1.30.12/#_1","title":"\u4e3b\u673a\u73af\u5883\u51c6\u5907","text":"<p>\u4f7f\u7528Kubeadm\u5feb\u901f\u90e8\u7f72Kubernetes\u96c6\u7fa4\uff0c\u64cd\u4f5c\u7cfb\u7edf\u4e3aUbuntu 24.04.2 LTS(noble)\uff0c\u7528\u5230\u7684\u5404\u76f8\u5173\u7a0b\u5e8f\u7248\u672c\u5982\u4e0b:</p> <ul> <li>Kubernetes: v1.30.12</li> <li>Contianerd: v1.7.28</li> <li>Calico: v3.29.6</li> </ul> \u4e3b\u673a\u540d IP \u89d2\u8272 k8s-master01 192.168.1.111 master k8s-worker01 192.168.1.121 worker k8s-worker02 192.168.1.122 worker k8s-worker03 192.168.1.123 worker"},{"location":"k8s/kubeadm-v1.30.12/#1","title":"1.\u914d\u7f6e\u56fd\u5185\u6e90","text":"<ul> <li>Apt\u6e90\u7801</li> </ul> <pre><code>cat &gt; /etc/apt/sources.list.d/ubuntu.list &lt;&lt; 'EOF'\ndeb https://mirrors.aliyun.com/ubuntu/ noble main restricted universe multiverse\ndeb-src https://mirrors.aliyun.com/ubuntu/ noble main restricted universe multiverse\n\ndeb https://mirrors.aliyun.com/ubuntu/ noble-security main restricted universe multiverse\ndeb-src https://mirrors.aliyun.com/ubuntu/ noble-security main restricted universe multiverse\n\ndeb https://mirrors.aliyun.com/ubuntu/ noble-updates main restricted universe multiverse\ndeb-src https://mirrors.aliyun.com/ubuntu/ noble-updates main restricted universe multiverse\n\n# deb https://mirrors.aliyun.com/ubuntu/ noble-proposed main restricted universe multiverse\n# deb-src https://mirrors.aliyun.com/ubuntu/ noble-proposed main restricted universe multiverse\n\ndeb https://mirrors.aliyun.com/ubuntu/ noble-backports main restricted universe multiverse\ndeb-src https://mirrors.aliyun.com/ubuntu/ noble-backports main restricted universe multiverse\nEOF\n</code></pre> <ul> <li>Docker\u6e90</li> </ul> <pre><code># step 1: \u5b89\u88c5\u5fc5\u8981\u7684\u4e00\u4e9b\u7cfb\u7edf\u5de5\u5177\nsudo apt-get update\nsudo apt-get install ca-certificates curl gnupg\n\n# step 2: \u4fe1\u4efb Docker \u7684 GPG \u516c\u94a5\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\n\n# Step 3: \u5199\u5165\u8f6f\u4ef6\u6e90\u4fe1\u606f\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.aliyun.com/docker-ce/linux/ubuntu \\\n  \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\n# Step 4: \u5b89\u88c5Docker\nsudo apt-get update\n# \u5b89\u88c5\u6307\u5b9a\u7248\u672c\u7684Docker-CE:\n# Step 1: \u67e5\u627eDocker-CE\u7684\u7248\u672c:\n# apt-cache madison docker-ce\n#   docker-ce | 17.03.1~ce-0~ubuntu-xenial | https://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages\n#   docker-ce | 17.03.0~ce-0~ubuntu-xenial | https://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages\n# Step 2: \u5b89\u88c5\u6307\u5b9a\u7248\u672c\u7684Docker-CE: (VERSION\u4f8b\u5982\u4e0a\u9762\u768417.03.1~ce-0~ubuntu-xenial)\n# sudo apt-get -y install docker-ce=[VERSION]\n</code></pre> <ul> <li>Kubernetes\u6e90</li> </ul> <pre><code>apt-get update &amp;&amp; apt-get install -y apt-transport-https\ncurl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/deb/Release.key |\n    gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\necho \"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/deb/ /\" |\n    tee /etc/apt/sources.list.d/kubernetes.list\napt-get update\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#2","title":"2.\u4e3b\u673a\u540d\u89e3\u6790","text":"<pre><code>cat &gt;&gt; /etc/hosts &lt;&lt; 'EOF'\n192.168.1.111 k8s-master01\n192.168.1.121 k8s-worker01\n192.168.1.122 k8s-worker02\n192.168.1.123 k8s-worker03\n# k8s-vip \u9884\u7559\u540e\u671f\u6269\u5c55\u9ad8\u53ef\u7528\u96c6\u7fa4\n192.168.1.111 k8s-vip\nEOF\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#3selinuxubuntuselinux","title":"3.\u5173\u95ed\u9632\u706b\u5899\u548cselinux(Ubuntu\u4e0d\u7528\u7ba1SELinux)","text":"<pre><code>sed -i 's/.*swap.*/#&amp;/' /etc/fstab\nswapoff -a &amp;&amp; sysctl -w vm.swappiness=0\nsystemctl  mask swap.target\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#4swap","title":"4.\u5173\u95edswap\u5206\u533a","text":"<pre><code>sed -i 's/.*swap.*/#&amp;/' /etc/fstab\nswapoff -a &amp;&amp; sysctl -w vm.swappiness=0\nsystemctl  mask swap.target\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#5","title":"5.\u65f6\u533a\u8ddf\u65f6\u95f4\u540c\u6b65","text":"<pre><code>timedatectl  set-timezone Asia/Shanghai\napt install -y chrony\ncat  &gt; /etc/chrony/chrony.conf &lt;&lt; 'EOF'\npool ntp.aliyun.com       iburst maxsources 4\nkeyfile /etc/chrony/chrony.keys\ndriftfile /var/lib/chrony/chrony.drift\nlogdir /var/log/chrony\nmaxupdateskew 100.0\nrtcsync\nmakestep 1 3\nEOF\nsystemctl restart chrony.service &amp;&amp; systemctl  enable chrony.service\nchronyc sources\nMS Name/IP address         Stratum Poll Reach LastRx Last sample\n===============================================================================\n^* 203.107.6.88                  2   6     7     1  -4176us[ +806us] +/-   29ms\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#6ipvs","title":"6.\u52a0\u8f7dIPVS\u6a21\u5757","text":"<pre><code>apt install ipset ipvsadm -y\ncat &gt;&gt; /etc/modules-load.d/k8s.conf &lt;&lt; 'EOF'\nbr_netfilter\nip_vs\nip_vs_rr\nip_vs_wrr\nip_vs_sh\nnf_conntrack\nnf_nat\noverlay\nvxlan\niptable_nat\nxt_MASQUERADE\nEOF\nsystemctl restart systemd-modules-load\nlsmod | grep -E 'br_netfilter|ip_vs|nf_conntrack|overlay|vxlan'\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#7","title":"7.\u5185\u6838\u53c2\u6570\u4f18\u5316","text":"<pre><code>cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; 'EOF'\n# \u5f00\u542fIPv4\u8f6c\u53d1\nnet.ipv4.ip_forward = 1\n# \u5141\u8bb8\u6865\u63a5\u7684\u6d41\u91cf\u8fdb\u5165iptables/netfilter\nnet.bridge.bridge-nf-call-iptables = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\n# \u4f18\u5316\u8fde\u63a5\u8ddf\u8e2a\u8868\u5927\u5c0f\uff0c\u9632\u6b62\u5927\u89c4\u6a21\u8fde\u63a5\u7206\u6389\nnet.netfilter.nf_conntrack_max = 2310720\n# TCP\u4f18\u5316\uff08\u7f29\u77ed TIME_WAIT\uff0c\u5feb\u901f\u56de\u6536\u8fde\u63a5\uff09\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_fin_timeout = 15\nnet.ipv4.tcp_keepalive_time = 600\nnet.ipv4.tcp_keepalive_intvl = 30\nnet.ipv4.tcp_keepalive_probes = 5\n# \u5185\u5b58\u76f8\u5173\u4f18\u5316\uff08\u9632\u6b62OOM\uff09\nvm.swappiness = 0\nvm.overcommit_memory = 1\nvm.panic_on_oom = 0\n# \u6587\u4ef6\u53e5\u67c4\u9650\u5236\nfs.file-max = 52706963\n# \u7f51\u7edc\u5c42\u9762\u4f18\u5316\nnet.core.somaxconn = 32768\nnet.core.netdev_max_backlog = 16384\nnet.ipv4.tcp_max_syn_backlog = 16384\nEOF\nsysctl --system\ncat &gt;&gt; /etc/security/limits.conf &lt;&lt; 'EOF'\n* soft nofile 1048576\n* hard nofile 1048576\n* soft nproc 1048576\n* hard nproc 1048576\n* soft memlock unlimited\n* hard memlock unlimited\nEOF\nulimit  -n 64435\nulimit  -s 10240\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#_2","title":"\u5b89\u88c5\u5bb9\u5668\u8fd0\u884c\u65f6","text":""},{"location":"k8s/kubeadm-v1.30.12/#1_1","title":"1.\u5b89\u88c5\u6307\u5b9a\u7248\u672c\u7684\u5bb9\u5668\u8fd0\u884c\u65f6","text":"<pre><code>apt-cache madison containerd\napt install -y containerd=1.7.28-0ubuntu1~24.04.1\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#2contianerd","title":"2.\u914d\u7f6econtianerd","text":"<pre><code>mkdir -pv /etc/containerd\ncontainerd config default | sudo tee /etc/containerd/config.toml\n# \u4fee\u6539cgroup Driver\u4e3asystemd\nsed -ri 's@SystemdCgroup = false@SystemdCgroup = true@' /etc/containerd/config.toml\n# \u66f4\u6539sandbox_image\nsed -ri 's@registry.k8s.io\\/pause:3.8@registry.cn-hangzhou.aliyuncs.com\\/google_containers\\/pause:3.9@' /etc/containerd/config.toml\n# \u914d\u7f6econtainerd \u7684\u955c\u50cf\u5b58\u50a8\u76ee\u5f55\nsed -i 's@root = \"/var/lib/containerd\"@root = \"/data/containerd\"@g' /etc/containerd/config.toml\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#3","title":"3.\u914d\u7f6e\u52a0\u901f\u5668","text":"<pre><code>sed -i 's@config_path = \"\"@config_path = \"\\/etc\\/containerd\\/certs.d\\/\"@g' /etc/containerd/config.toml\n# docker.io \u955c\u50cf\u52a0\u901f\nmkdir -p /etc/containerd/certs.d/docker.io\ncat &gt; /etc/containerd/certs.d/docker.io/hosts.toml &lt;&lt; 'EOF'\nserver = \"https://docker.io\" # \u6e90\u955c\u50cf\u5730\u5740\n\n[host.\"https://docker.1ms.run\"]\n  capabilities = [\"pull\",\"resolve\"]\n\n[host.\"https://docker.m.daocloud.io\"] # \u9053\u5ba2-\u955c\u50cf\u52a0\u901f\u5730\u5740\n  capabilities = [\"pull\",\"resolve\"]\n\n[host.\"https://dockerproxy.com\"] # \u955c\u50cf\u52a0\u901f\u5730\u5740\n  capabilities = [\"pull\", \"resolve\"]\n\n[host.\"https://docker.mirrors.sjtug.sjtu.edu.cn\"] # \u4e0a\u6d77\u4ea4\u5927-\u955c\u50cf\u52a0\u901f\u5730\u5740\n  capabilities = [\"pull\",\"resolve\"]\n\n[host.\"https://docker.mirrors.ustc.edu.cn\"] # \u4e2d\u79d1\u5927-\u955c\u50cf\u52a0\u901f\u5730\u5740\n  capabilities = [\"pull\",\"resolve\"]\n\n[host.\"https://docker.nju.edu.cn\"] # \u5357\u4eac\u5927\u5b66-\u955c\u50cf\u52a0\u901f\u5730\u5740\n  capabilities = [\"pull\",\"resolve\"]\n\n[host.\"https://registry-1.docker.io\"]\n  capabilities = [\"pull\",\"resolve\",\"push\"]\nEOF\n\n# registry.k8s.io \u955c\u50cf\u52a0\u901f\nmkdir -p /etc/containerd/certs.d/registry.k8s.io\ncat &gt; /etc/containerd/certs.d/registry.k8s.io/hosts.toml &lt;&lt; 'EOF'\nserver = \"https://registry.k8s.io\"\n\n[host.\"https://k8s.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\", \"push\"]\nEOF\n\n# quay.io \u955c\u50cf\u52a0\u901f\nmkdir -p /etc/containerd/certs.d/quay.io\ncat &gt; /etc/containerd/certs.d/quay.io/hosts.toml &lt;&lt; 'EOF'\nserver = \"https://quay.io\"\n\n[host.\"https://quay.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\", \"push\"]\nEOF\n\n# docker.elastic.co\u955c\u50cf\u52a0\u901f\nmkdir -p /etc/containerd/certs.d/docker.elastic.co\ntee /etc/containerd/certs.d/docker.elastic.co/hosts.toml &lt;&lt; 'EOF'\nserver = \"https://docker.elastic.co\"\n\n[host.\"https://elastic.m.daocloud.io\"]\n  capabilities = [\"pull\", \"resolve\", \"push\"]\nEOF\nsystemctl daemon-reload &amp;&amp;  systemctl restart containerd &amp;&amp; systemctl enable containerd\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#4crictl","title":"4.\u5b89\u88c5crictl\u5ba2\u6237\u7aef","text":"<pre><code>wget https://ghfast.top/https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.24.0/crictl-v1.24.0-linux-amd64.tar.gz\ntar -zxvf crictl-v1.24.0-linux-amd64.tar.gz -C /usr/local/bin\ncat &gt; /etc/crictl.yaml &lt;&lt;EOF\nruntime-endpoint: unix:///var/run/containerd/containerd.sock\nimage-endpoint: unix:///var/run/containerd/containerd.sock\ntimeout: 10\ndebug: false\npull-image-on-create: false\nEOF\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#kubernetes","title":"\u5b89\u88c5Kubernetes\u96c6\u7fa4","text":""},{"location":"k8s/kubeadm-v1.30.12/#1kubeadm","title":"1.\u5b89\u88c5kubeadm\u8f6f\u4ef6\u5305","text":"<pre><code>apt-cache madison kubeadm\napt install kubeadm=1.30.12-1.1 kubelet=1.30.12-1.1 kubectl=1.30.12-1.1\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#2kubelet","title":"2.\u914d\u7f6ekubelet\u5f00\u673a\u81ea\u542f","text":"<pre><code>systemctl enable --now kubelet\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#3_1","title":"3.\u96c6\u7fa4\u5b89\u88c5","text":""},{"location":"k8s/kubeadm-v1.30.12/#31master","title":"3.1.Master \u8282\u70b9\u521d\u59cb\u5316","text":"<pre><code># \u63d0\u524d\u62c9\u53d6\u955c\u50cf\nkubeadm config images pull --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers --kubernetes-version=1.30.12\nkubeadm init \\\n  --kubernetes-version=1.30.12 \\\n  --control-plane-endpoint=\"k8s-vip\" \\\n  --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers \\\n  --pod-network-cidr=10.244.0.0/16 \\\n  --service-cidr=10.96.0.0/12 \\\n  --token-ttl=0 \\\n  --upload-certs|tee kubeadm.log\n[init] Using Kubernetes version: v1.30.12\n[preflight] Running pre-flight checks\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"ca\" certificate and key\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [k8s-master01 k8s-vip kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.111]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Generating \"front-proxy-ca\" certificate and key\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/ca\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8s-master01 localhost] and IPs [192.168.1.111 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8s-master01 localhost] and IPs [192.168.1.111 127.0.0.1 ::1]\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"sa\" key and public key\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"super-admin.conf\" kubeconfig file\n[kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Starting the kubelet\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\"\n[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s\n[kubelet-check] The kubelet is healthy after 1.002218069s\n[api-check] Waiting for a healthy API server. This can take up to 4m0s\n[api-check] The API server is healthy after 5.504002718s\n[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config\" in namespace kube-system with the configuration for the kubelets in the cluster\n[upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[upload-certs] Using certificate key:\nb02bcd4ca23ffb9ea4aaf72cd7fecb745592efd7acb50ce49d651b0c676780c5\n[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]\n[mark-control-plane] Marking the node k8s-master01 as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]\n[bootstrap-token] Using token: 2zzmat.b1omkhqhuns4s30x\n[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles\n[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of the control-plane node running the following command on each as root:\n\n  kubeadm join k8s-vip:6443 --token 2zzmat.b1omkhqhuns4s30x \\\n    --discovery-token-ca-cert-hash sha256:66d67a3c65fb6a32e5e67b1194ec9a49fc826f1ae1d9ab92b3a2932e49a82d5e \\\n    --control-plane --certificate-key b02bcd4ca23ffb9ea4aaf72cd7fecb745592efd7acb50ce49d651b0c676780c5\n\nPlease note that the certificate-key gives access to cluster sensitive data, keep it secret!\nAs a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use\n\"kubeadm init phase upload-certs --upload-certs\" to reload certs afterward.\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join k8s-vip:6443 --token 2zzmat.b1omkhqhuns4s30x \\\n    --discovery-token-ca-cert-hash sha256:66d67a3c65fb6a32e5e67b1194ec9a49fc826f1ae1d9ab92b3a2932e49a82d5e\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#32kubectl","title":"3.2.\u914d\u7f6ekubectl\u547d\u4ee4","text":"<pre><code>mkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\nkubectl  get nodes\nNAME           STATUS     ROLES           AGE    VERSION\nk8s-master01   NotReady   control-plane   107s   v1.30.12\nkubectl  get pods -A\nNAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE\nkube-system   coredns-6d58d46f65-2fg6x               0/1     Pending   0          93s\nkube-system   coredns-6d58d46f65-p66nm               0/1     Pending   0          93s\nkube-system   etcd-k8s-master01                      1/1     Running   0          107s\nkube-system   kube-apiserver-k8s-master01            1/1     Running   0          107s\nkube-system   kube-controller-manager-k8s-master01   1/1     Running   0          110s\nkube-system   kube-proxy-m2wnr                       1/1     Running   0          93s\nkube-system   kube-scheduler-k8s-master01            1/1     Running   0          109s\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#33worker","title":"3.3.\u52a0\u5165worker\u8282\u70b9","text":"<pre><code>kubeadm join k8s-vip:6443 --token 2zzmat.b1omkhqhuns4s30x \\\n    --discovery-token-ca-cert-hash sha256:66d67a3c65fb6a32e5e67b1194ec9a49fc826f1ae1d9ab92b3a2932e49a82d5e\nkubectl  get nodes -owide\nNAME           STATUS     ROLES           AGE     VERSION    INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME\nk8s-master01   NotReady   control-plane   3m58s   v1.30.12   192.168.1.111   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-85-generic   containerd://1.7.28\nk8s-worker01   NotReady   &lt;none&gt;          52s     v1.30.12   192.168.1.121   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-85-generic   containerd://1.7.28\nk8s-worker02   NotReady   &lt;none&gt;          27s     v1.30.12   192.168.1.122   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-85-generic   containerd://1.7.28\nk8s-worker03   NotReady   &lt;none&gt;          23s     v1.30.12   192.168.1.123   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-85-generic   containerd://1.7.28\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#4","title":"4.\u90e8\u7f72\u7f51\u7edc\u63d2\u4ef6","text":"<p>\u7248\u672c\u5bf9\u5e94\u5173\u7cfb:<code>https://docs.tigera.io/calico/3.29/getting-started/kubernetes/requirements</code></p>"},{"location":"k8s/kubeadm-v1.30.12/#41","title":"4.1.\u83b7\u53d6\u90e8\u7f72\u6587\u4ef6","text":"<pre><code>curl https://raw.githubusercontent.com/projectcalico/calico/v3.29.6/manifests/calico.yaml -O\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#42calico","title":"4.2.\u914d\u7f6ecalico","text":"<pre><code># \u914d\u7f6ePod\u7f51\u7edc\nsed -i 's@# - name: CALICO_IPV4POOL_CIDR@- name: CALICO_IPV4POOL_CIDR@g' calico.yaml\nsed -i 's@#   value: \"192.168.0.0/16\"@  value: \"10.244.0.0/16\"@g' calico.yaml\n# \u9ed8\u8ba4\u4e3a26\u4f4d\u63a9\u7801\uff0c\u6539\u621024\uff0c\u53ef\u7528\u5730\u5740\u6709\u591a\u5c11\u4e2a2^8 -2  = 254 \u4e2a\nsed -i '/value: \"10\\.244\\.0\\.0\\/16\"/a\\            - name: CALICO_IPV4POOL_BLOK_SIZE\\n              value: \"24\"'  calico.yaml\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#43calico","title":"4.3.\u90e8\u7f72calico","text":"<pre><code>kubectl apply -f calico.yaml\nkubectl  get pod -l k8s-app=calico-node -n kube-system\nNAME                READY   STATUS    RESTARTS   AGE\ncalico-node-l95lq   1/1     Running   0          5m46s\ncalico-node-lz5s9   1/1     Running   0          5m46s\ncalico-node-n6mh5   1/1     Running   0          5m46s\ncalico-node-v2q6d   1/1     Running   0          5m46s\nroot@k8s-master01:~/v1.30.12/calico# kubectl  get nodes\nNAME           STATUS   ROLES           AGE    VERSION\nk8s-master01   Ready    control-plane   169m   v1.30.12\nk8s-worker01   Ready    &lt;none&gt;          166m   v1.30.12\nk8s-worker02   Ready    &lt;none&gt;          166m   v1.30.12\nk8s-worker03   Ready    &lt;none&gt;          166m   v1.30.12\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#5ipvs","title":"5.\u4fee\u6539\u96c6\u7fa4\u7f51\u7edc\u4e3aIPVS","text":"<pre><code>kubectl  edit cm/kube-proxy -n kube-system -o yaml\n  ipvs:\n    ...\n    strictARP: true\n  mode: \"ipvs\"\nkubectl -n kube-system rollout restart daemonset kube-proxy\nipvsadm -Ln\nIP Virtual Server version 1.2.1 (size=4096)\nProt LocalAddress:Port Scheduler Flags\n  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn\nTCP  10.96.0.1:443 rr\n  -&gt; 192.168.1.111:6443           Masq    1      1          0\nTCP  10.96.0.10:53 rr\n  -&gt; 10.244.69.193:53             Masq    1      0          0\n  -&gt; 10.244.69.194:53             Masq    1      0          0\nTCP  10.96.0.10:9153 rr\n  -&gt; 10.244.69.193:9153           Masq    1      0          0\n  -&gt; 10.244.69.194:9153           Masq    1      0          0\nUDP  10.96.0.10:53 rr\n  -&gt; 10.244.69.193:53             Masq    1      0          0\n  -&gt; 10.244.69.194:53             Masq    1      0          0\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#_3","title":"\u9a8c\u8bc1\u96c6\u7fa4","text":""},{"location":"k8s/kubeadm-v1.30.12/#1deploysvc","title":"1.\u521b\u5efadeploy\u548csvc","text":"<pre><code>kubectl  create deployment myapp --image=ikubernetes/myapp:v1 --replicas=5\nkubectl expose deployment myapp --port=80 --target-port=80 --type=\"NodePort\"\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#2podsvc","title":"2.\u67e5\u770bpod\u8ddfsvc","text":"<pre><code>kubectl  get pod -A -o wide -l app=myapp\nNAMESPACE   NAME                    READY   STATUS    RESTARTS   AGE     IP              NODE           NOMINATED NODE   READINESS GATES\ndefault     myapp-64b9c4c64-bsszd   1/1     Running   0          18s     10.244.39.196   k8s-worker03   &lt;none&gt;           &lt;none&gt;\ndefault     myapp-64b9c4c64-dnkvt   1/1     Running   0          17s     10.244.69.197   k8s-worker02   &lt;none&gt;           &lt;none&gt;\ndefault     myapp-64b9c4c64-sltln   1/1     Running   0          5m5s    10.244.79.67    k8s-worker01   &lt;none&gt;           &lt;none&gt;\ndefault     myapp-64b9c4c64-x9cn6   1/1     Running   0          2m25s   10.244.79.68    k8s-worker01   &lt;none&gt;           &lt;none&gt;\ndefault     myapp-64b9c4c64-zcm96   1/1     Running   0          17s     10.244.39.197   k8s-worker03   &lt;none&gt;           &lt;none&gt;\nkubectl  get svc myapp\nNAME    TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\nmyapp   NodePort   10.100.179.119   &lt;none&gt;        80:32203/TCP   2s\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#3svcpod","title":"3.\u901a\u8fc7svc\u8bbf\u95eepod","text":"<pre><code>for i in `seq 5`;do curl 10.100.179.119/hostname.html;done\nmyapp-64b9c4c64-x9cn6\nmyapp-64b9c4c64-sltln\nmyapp-64b9c4c64-dnkvt\nmyapp-64b9c4c64-zcm96\nmyapp-64b9c4c64-bsszd\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#4-dns","title":"4. \u9a8c\u8bc1dns","text":"<p><pre><code>apt install dnsutils\nkubectl get svc -n kube-system\nNAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE\nkube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   3h7m\ndig -t A myapp.default.svc.cluster.local @10.96.0.10\n\n; &lt;&lt;&gt;&gt; DiG 9.18.39-0ubuntu0.24.04.1-Ubuntu &lt;&lt;&gt;&gt; -t A myapp.default.svc.cluster.local @10.96.0.10\n;; global options: +cmd\n;; Got answer:\n;; WARNING: .local is reserved for Multicast DNS\n;; You are currently testing what happens when an mDNS query is leaked to DNS\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 10731\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1232\n; COOKIE: 3f502025a920150a (echoed)\n;; QUESTION SECTION:\n;myapp.default.svc.cluster.local. IN    A\n\n;; ANSWER SECTION:\nmyapp.default.svc.cluster.local. 30 IN  A   10.100.179.119\n\n;; Query time: 2 msec\n;; SERVER: 10.96.0.10#53(10.96.0.10) (UDP)\n;; WHEN: Tue Oct 21 01:04:18 CST 2025\n;; MSG SIZE  rcvd: 119\n</code></pre> <pre><code>kubectl  exec -it myapp-64b9c4c64-bsszd -- sh\n/ # wget -O - -q myapp\nHello MyApp | Version: v1 | &lt;a href=\"hostname.html\"&gt;Pod Name&lt;/a&gt;\n/ # wget -O - -q myapp.default\nHello MyApp | Version: v1 | &lt;a href=\"hostname.html\"&gt;Pod Name&lt;/a&gt;\n/ # wget -O - -q myapp.default.svc.cluster.local.\nHello MyApp | Version: v1 | &lt;a href=\"hostname.html\"&gt;Pod Name&lt;/a&gt;\n</code></pre></p>"},{"location":"k8s/kubeadm-v1.30.12/#add-on","title":"\u5b89\u88c5\u63d2\u4ef6Add-On","text":""},{"location":"k8s/kubeadm-v1.30.12/#metrics-server","title":"metrics-server","text":""},{"location":"k8s/kubeadm-v1.30.12/#dashboard","title":"dashboard","text":""},{"location":"k8s/kubeadm-v1.30.12/#_4","title":"\u5378\u8f7d\u96c6\u7fa4","text":""},{"location":"k8s/kubeadm-v1.30.12/#1_2","title":"1.\u5378\u8f7d\u6574\u4e2a\u96c6\u7fa4","text":"<p>\u5148\u62c6\u9664\u5404\u4e2a\u5de5\u4f5c\u8282\u70b9\uff0c\u5728\u62c6\u9664\u63a7\u5236\u5e73\u9762</p> <pre><code>kubeadm reset\nrm -rf /etc/kubernetes /var/lib/kubelet/ /var/lib/cni/ /etc/cni/net.d/ /var/lib/etcd/\n</code></pre>"},{"location":"k8s/kubeadm-v1.30.12/#2_1","title":"2.\u62c6\u9664\u5355\u4e2a\u5de5\u4f5c\u8282\u70b9","text":"<pre><code># 1. \u7981\u6b62\u8c03\u5ea6\nkubectl cordon k8s-worker03\n# 2. \u6392\u7a7a\u8282\u70b9\nkubectl drain k8s-worker03\n# 3. \u5220\u9664\u8282\u70b9\nkubectl delete node  k8s-worker03\n# 4. \u6267\u884creset\u8ddf\u540e\u7eed\u7684\u6e05\u7406\u5de5\u4f5c\nkubeadm reset\nrm -rf /etc/kubernetes /var/lib/kubelet/ /var/lib/cni/ /etc/cni/net.d/ /var/lib/etcd/\n</code></pre>"}]}